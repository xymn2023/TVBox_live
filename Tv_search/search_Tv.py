import random, requests, os, threading, time, sys, shutil
from lxml import etree
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- è·¯å¾„å¼ºåˆ¶å®šä½ ---
# æ— è®ºä»å“ªé‡Œè¿è¡Œï¼Œéƒ½ä»¥è„šæœ¬æ‰€åœ¨ä½ç½®ä¸ºåŸºå‡†
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
ROOT_DIR = os.path.dirname(BASE_DIR)
sys.path.append(ROOT_DIR)

# å°è¯•å¯¼å…¥ä»£ç†æ¨¡å—
try:
    from proxyTest import get_valid_proxies
except ImportError:
    def get_valid_proxies(): return None

def get_url(name):
    print(f"æ­£åœ¨æœç´¢é¢‘é“: {name}...")
    ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'
    opt = Options()
    opt.add_argument("--headless")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument(f"user-agent={ua}")
    
    # æ˜¾å¼æŒ‡å®šé©±åŠ¨ä½ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰æˆ–ç›´æ¥è°ƒç”¨
    try:
        driver = webdriver.Chrome(options=opt)
    except Exception as e:
        print(f"æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
        return []

    m3u8_list = []
    try:
        driver.get('http://tonkiang.us/')
        search_box = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'search')))
        search_box.send_keys(name)
        driver.find_element(By.NAME, 'Submit').click()
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(2) 
        root = etree.HTML(driver.page_source)
        results = root.xpath("//div[@class='resultplus']//tba")
        for res in results:
            if res.text and "m3u8" in res.text:
                m3u8_list.append(res.text.strip())
        print(f" >> æ‰¾åˆ° {len(m3u8_list)} ä¸ªæº")
    except Exception as e:
        print(f"æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
    finally:
        driver.quit()
    return m3u8_list

def download_m3u8(url, name, speed_limit=1.0):
    try:
        # å¢åŠ è¶…æ—¶æ§åˆ¶ï¼Œé˜²æ­¢çº¿ç¨‹å¡æ­»
        resp = requests.get(url, timeout=10)
        if resp.status_code != 200: return
        
        m3u8_content = resp.text
        # ç®€å•çš„åµŒå¥—è·³è½¬å¤„ç†
        if not "#EXTM3U" in m3u8_content: return
        
        lines = [l.strip() for l in m3u8_content.split('\n') if l and not l.startswith('#')]
        if len(lines) == 0: return
        
        # å¦‚æœæ˜¯åµŒå¥—çš„ m3u8
        if lines[0].endswith(".m3u8"):
            nest_url = lines[0] if lines[0].startswith("http") else url.rsplit('/', 1)[0] + '/' + lines[0]
            return download_m3u8(nest_url, name, speed_limit)

        # æµ‹é€Ÿé€»è¾‘
        start = time.time()
        seg_url = lines[0] if lines[0].startswith("http") else url.rsplit('/', 1)[0] + '/' + lines[0]
        seg_resp = requests.get(seg_url, timeout=10, stream=True)
        size = len(seg_resp.content)
        duration = time.time() - start
        
        speed = size / duration / (1024 * 1024) if duration > 0 else 0
        if speed >= speed_limit:
            print(f" [OK] {åå­—} é€Ÿåº¦: {speed:.2f} MB/s")
            save_path = os.path.join(BASE_DIR, TV_NAME, f"{åå­—}.txt")
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with æ‰“å¼€(save_path, 'a', encoding='utf-8') as f:
                f.æ’°å†™(f"{åå­—},{url}\n")
    except:
        pass

if __name__ == '__main__':
    # 1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    TV_NAMES = ['ğŸ‡¨ğŸ‡³å¤®è§†é¢‘é“']
    OUT_FILE = os.path.join(ROOT_DIR, 'live.txt')
    
    print(f"å·¥ä½œç›®å½•: {BASE_DIR}")
    
    for TV_NAME in TV_NAMES:
        input_file = os.path.join(BASE_DIR, f"{TV_NAME}.txt")
        if not os.path.exists(input_file):
            print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}")
            continue

        # æ¸…ç†æ—§ç›®å½•
        target_dir = os.path.join(BASE_DIR, TV_NAME)
        if os.path.exists(target_dir): shutil.rmtree(target_dir)

        with æ‰“å¼€(input_file, 'r', encoding='utf-8') as f:
            channels = [l.strip() for l in f if l.strip()]

        for channel in channels:
            urls = get_url(channel)
            threads = []
            for u in urls:
                t = threading.Thread(target=download_m3u8, args=(u, channel))
                t.start()
                threads.append(t)
            for t in threads: t.join(timeout=15)

        # åˆå¹¶ç»“æœ
        if os.path.exists(target_dir):
            with æ‰“å¼€(OUT_FILE, 'a', encoding='utf-8') as out:
                out.æ’°å†™(f"{TV_NAME},#genre#\n")
                for txt in os.listdir(target_dir):
                    with æ‰“å¼€(os.path.join(target_dir, txt), 'r', encoding='utf-8') as f:
                        out.æ’°å†™(f.read())
    
    # å»é‡
    if os.path.exists(OUT_FILE):
        with æ‰“å¼€(OUT_FILE, 'r', encoding='utf-8') as f:
            lines = list(dict.fromkeys(f.readlines()))
        with æ‰“å¼€(OUT_FILE, 'w', encoding='utf-8') as f:
            f.writelines(lines)
    print("ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")
